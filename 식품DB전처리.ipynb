{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "G4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tS1Y7ZyRE13m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def preprocess_nutrition_data(df):\n",
        "    # 1. 단위를 추출하기 위한 정규표현식 (g, mg, ug, mcg 등)\n",
        "    # 컬럼명 예: \"단백질(g)\", \"나트륨(mg)\", \"비타민A(ug)\"\n",
        "    unit_pattern = re.compile(r'\\((g|mg|ug|mcg)\\)', re.IGNORECASE)\n",
        "\n",
        "    # 단위 변환 계수\n",
        "    unit_map = {\n",
        "        'g': 1.0,\n",
        "        'mg': 0.001,\n",
        "        'ug': 0.000001,\n",
        "        'mcg': 0.000001\n",
        "    }\n",
        "\n",
        "    # 변환된 g 값을 저장할 임시 데이터프레임\n",
        "    df_in_grams = pd.DataFrame()\n",
        "    nutrient_cols = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        match = unit_pattern.search(col)\n",
        "        if match:\n",
        "            unit = match.group(1).lower()\n",
        "            nutrient_cols.append(col)\n",
        "            # 해당 컬럼의 값을 g 단위로 환산\n",
        "            df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
        "\n",
        "    # 2. 행별 성분 총합 계산 (100g 당 함량이므로 모든 성분의 합은 100g 이하여야 함)\n",
        "    df['total_grams'] = df_in_grams.sum(axis=1)\n",
        "\n",
        "    # 3. 이상치 판단 및 삭제 (100g을 초과하는 행 제외)\n",
        "    # 부동 소수점 오차를 고려하여 약간의 여유(예: 100.0001)를 둘 수 있습니다.\n",
        "    cleaned_df = df[df['total_grams'] <= 100.0001].copy()\n",
        "\n",
        "    # 결과 확인을 위해 추가했던 total_grams 컬럼 삭제 (선택 사항)\n",
        "    # cleaned_df = cleaned_df.drop(columns=['total_grams'])\n",
        "\n",
        "    print(f\"전체 데이터: {len(df)}행\")\n",
        "    print(f\"삭제된 이상치: {len(df) - len(cleaned_df)}행\")\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "# 함수 실행\n",
        "df = pd.read_excel('/content/20251229_음식DB 19495건.xlsx')\n",
        "cleaned_df = preprocess_nutrition_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHhj2CyOCQuD",
        "outputId": "96dc8aea-2215-4c9f-c9b4-5281b16f09e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터: 19495행\n",
            "삭제된 이상치: 2096행\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n",
            "/tmp/ipython-input-3434407710.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_in_grams[col] = pd.to_numeric(df[col], errors='coerce').fillna(0) * unit_map[unit]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2IaozwgTmbe",
        "outputId": "1d7a72b1-3771-4f6b-8555-c85bc9ef50c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    식품코드                   식품명 데이터구분코드 데이터구분명  식품기원코드  \\\n",
            "482  D201-013000000-0001  리소토/리조또_스파이시 씨푸드 리조또       D     음식       2   \n",
            "483  D201-013000000-0002     리소토/리조또_치킨 크림 리조또       D     음식       2   \n",
            "484  D201-013000000-0003      리소토/리조또_베이컨크림리조또       D     음식       2   \n",
            "485  D201-017000000-0001        볶음밥_갈비천왕 치즈 치밥       D     음식       2   \n",
            "486  D201-017000000-0002          볶음밥_달걀듬뿍 볶음밥       D     음식       2   \n",
            "\n",
            "                      식품기원명  식품대분류코드 식품대분류명  대표식품코드    대표식품명  ...  출처코드  \\\n",
            "482  외식(프랜차이즈 등 업체 제공 영양정보)        1     밥류    1013  리소토/리조또  ...     3   \n",
            "483  외식(프랜차이즈 등 업체 제공 영양정보)        1     밥류    1013  리소토/리조또  ...     3   \n",
            "484  외식(프랜차이즈 등 업체 제공 영양정보)        1     밥류    1013  리소토/리조또  ...     3   \n",
            "485  외식(프랜차이즈 등 업체 제공 영양정보)        1     밥류    1017      볶음밥  ...     3   \n",
            "486  외식(프랜차이즈 등 업체 제공 영양정보)        1     밥류    1017      볶음밥  ...     3   \n",
            "\n",
            "          출처명  1인(회)분량 참고량  식품중량    업체명 데이터생성방법코드 데이터생성방법명     데이터생성일자  \\\n",
            "482  식품의약품안전처          NaN  241g    할리스         2       수집  2022-07-11   \n",
            "483  식품의약품안전처          NaN  241g    할리스         2       수집  2022-07-11   \n",
            "484  식품의약품안전처          NaN  457g  피자알볼로         2       수집  2025-09-30   \n",
            "485  식품의약품안전처          NaN  100g   굽네치킨         2       수집  2023-10-11   \n",
            "486  식품의약품안전처          NaN  100g   교촌치킨         2       수집  2023-10-11   \n",
            "\n",
            "       데이터기준일자  total_grams  \n",
            "482 2025-12-29     11.10600  \n",
            "483 2025-12-29     13.03700  \n",
            "484 2025-12-29      7.50800  \n",
            "485 2025-12-29     39.83721  \n",
            "486 2025-12-29      7.30500  \n",
            "\n",
            "[5 rows x 161 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9166c9bc",
        "outputId": "8f633f1d-aa79-4c66-ab37-8ec5f09afb69"
      },
      "source": [
        "print(cleaned_df.columns.tolist())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['식품코드', '식품명', '데이터구분코드', '데이터구분명', '식품기원코드', '식품기원명', '식품대분류코드', '식품대분류명', '대표식품코드', '대표식품명', '식품중분류코드', '식품중분류명', '식품소분류코드', '식품소분류명', '식품세분류코드', '식품세분류명', '영양성분함량기준량', '에너지(kcal)', '수분(g)', '단백질(g)', '지방(g)', '회분(g)', '탄수화물(g)', '당류(g)', '식이섬유(g)', '칼슘(mg)', '철(mg)', '인(mg)', '칼륨(mg)', '나트륨(mg)', '비타민A(μg RAE)', '레티놀(μg)', '베타카로틴(μg)', '티아민(mg)', '리보플라빈(mg)', '니아신(mg)', '비타민 C(mg)', '비타민 D(μg)', '콜레스테롤(mg)', '포화지방산(g)', '트랜스지방산(g)', '니코틴산(mg)', '니코틴아마이드(mg)', '비오틴(μg)', '비타민 B6 / 피리독신(mg)', '비타민 B12(μg)', '엽산(μg DFE)', '콜린(mg)', '판토텐산(mg)', '비타민 D2(μg)', '비타민 D3(μg)', '비타민 E(mg α-TE)', '알파 토코페롤(mg)', '베타 토코페롤(mg)', '감마 토코페롤(mg)', '델타 토코페롤(mg)', '알파 토코트리에놀(mg)', '베타 토코트리에놀(mg)', '감마 토코트리에놀(mg)', '델타 토코트리에놀(mg)', '비타민 K(μg)', '비타민 K1(μg)', '비타민 K2(μg)', '갈락토오스(g)', '과당(g)', '당알콜(g)', '맥아당(g)', '알룰로오스(g)', '에리스리톨(g)', '유당(g)', '자당(g)', '타가토스(g)', '포도당(g)', '불포화지방산(g)', 'EPA와 DHA의 합(mg)', '가돌레산(20:1) / 에이코센산(20:1)(mg)', '감마 리놀렌산(18:3(n-6))(mg)', '네르본산(24:1)(mg)', '도코사디에노산(22:2)(mg)', '도코사펜타에노산/토코사펜타엔산(22:5(n-3))(mg)', 'DHA / 도코사헥사에노산/도코사헥사엔산(22:6(n-3))(mg)', '디호모리놀렌산/에이코사트리에노산(20:3(n-3))(mg)', '라우르산(12:0)(mg)', '리그노세르산(24:0)(mg)', '리놀레산(18:2(n-6))(g)', '미리스톨레산(14:1)(mg)', '미리스트산(14:0)(mg)', '박센산(18:1(n-7))(mg)', '베헨산(22:0)(mg)', '부티르산(4:0)(mg)', '스테아르산(18:0)(mg)', '스테아리돈산(18:4(n-3))(mg)', '아라키돈산(20:4(n-6))(mg)', '아라키드산(20:0)(mg)', '알파 리놀렌산(18:3(n-3))(g)', '에루크산(22:1)(mg)', '에이코사디에노산(20:2(n-6))(mg)', '에이코사트리에노산(20:3(n-6))(mg)', 'EPA / 에이코사펜타에노산(20:5(n-3))(mg)', '오메가3 지방산(g)', '오메가6 지방산(g)', '올레산(18:1(n-9))(mg)', '카프로산(6:0)(mg)', '카프르산(10:0)(mg)', '카프릴산(8:0)(mg)', '트라이데칸산(13:0)(mg)', '트랜스 리놀레산(18:2t)(mg)', '트랜스 리놀렌산(18:3t)(mg)', '트랜스 올레산(18:1(n-9t)(mg)', '트리코산산(23:0)(mg)', '팔미톨레산(16:1)(mg)', '팔미트산(16:0)(mg)', '펜타데칸산(15:0)(mg)', '헨에이코산산(21:0)(mg)', '헵타데센산(17:1)(mg)', '헵타데칸산(17:0)(mg)', '구리(μg)', '마그네슘(mg)', '망간(mg)', '몰리브덴(μg)', '불소(mg)', '셀레늄(μg)', '아연(mg)', '염소(mg)', '요오드(μg)', '크롬(μg)', '아미노산(mg)', '필수아미노산(mg)', '비필수아미노산(mg)', '글루탐산(mg)', '글라이신(mg)', '라이신(mg)', '류신(mg)', '메티오닌(mg)', '발린(mg)', '세린(mg)', '시스테인(mg)', '아르기닌(mg)', '아스파르트산(mg)', '알라닌(mg)', '이소류신(mg)', '타우린(mg)', '트레오닌(mg)', '트립토판(mg)', '티로신(mg)', '페닐알라닌(mg)', '프롤린(mg)', '히스티딘(mg)', '카페인(mg)', '토코페롤(mg)', '토코트리에놀(mg)', '출처코드', '출처명', '1인(회)분량 참고량', '식품중량', '업체명', '데이터생성방법코드', '데이터생성방법명', '데이터생성일자', '데이터기준일자', 'total_grams']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def preprocess_nutrition_data(df):\n",
        "    # 1. 수치 데이터 정제 (결측치 처리 및 숫자 변환)\n",
        "    # 분석 대상이 될 수 있는 주요 컬럼 및 수치형 컬럼들을 정리\n",
        "    target_cols = ['탄수화물(g)', '단백질(g)', '지방(g)', '수분(g)', '회분(g)', '에너지(kcal)']\n",
        "\n",
        "    for col in df.columns:\n",
        "        # 데이터에 섞여 있을 수 있는 문자열(예: \"미량\", \"-\", \" \")을 처리\n",
        "        if df[col].dtype == 'object':\n",
        "            # 숫자가 아닌 값은 NaN으로 만든 뒤 0으로 채움\n",
        "            df[col] = pd.to_numeric(df[col].astype(str).str.replace(' ', ''), errors='coerce').fillna(0)\n",
        "\n",
        "        # 음수 데이터 보정 (물리적으로 불가능함)\n",
        "        if df[col].dtype in ['float64', 'int64']:\n",
        "            df.loc[df[col] < 0, col] = 0\n",
        "\n",
        "    # 2. 검증에 사용할 '최상위 카테고리' 컬럼 지정\n",
        "    # 이 성분들은 서로 독립적이며, 이들의 합은 100g을 넘을 수 없습니다.\n",
        "    major_nutrients = ['탄수화물(g)', '단백질(g)', '지방(g)', '수분(g)', '회분(g)']\n",
        "\n",
        "    # 데이터프레임에 실제 존재하는 컬럼만 필터링 (오류 방지)\n",
        "    existing_major = [col for col in major_nutrients if col in df.columns]\n",
        "\n",
        "    # 3. 행별 성분 총합 계산 (100g 기준 검증)\n",
        "    df['total_major_grams'] = df[existing_major].sum(axis=1)\n",
        "\n",
        "    # 4. 이상치 판단 및 삭제\n",
        "    # 실험 오차 및 반올림을 고려하여 100.5g을 임계값으로 설정\n",
        "    threshold = 100.5\n",
        "    cleaned_df = df[df['total_major_grams'] <= threshold].copy()\n",
        "\n",
        "    # 5. (선택) 에너지(kcal) 교차 검증 - 비정상 데이터 출력만 확인\n",
        "    # 탄(4) + 단(4) + 지(9) 계산식과 실제 에너지의 차이가 너무 큰 경우\n",
        "    #calculated_kcal = (df['탄수화물(g)'] * 4) + (df['단백질(g)'] * 4) + (df['지방(g)'] * 9)\n",
        "    #kcal_diff_mask = (abs(df['에너지(kcal)'] - calculated_kcal) > 500) # 차이가 500kcal 이상인 경우 예시\n",
        "\n",
        "    print(f\"--- 전처리 결과 요약 ---\")\n",
        "    print(f\"원본 데이터 행 수: {len(df)}\")\n",
        "    print(f\"삭제된 이상치(100g 초과): {len(df) - len(cleaned_df)}행\")\n",
        "    print(f\"남은 데이터 행 수: {len(cleaned_df)}\")\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "# 사용 예시:\n",
        "df = pd.read_excel('/content/20251229_음식DB 19495건.xlsx')\n",
        "cleaned_df = preprocess_nutrition_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg2Rn4ouUSJN",
        "outputId": "2dfef908-859c-49af-c1a5-c748f3f1afcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 전처리 결과 요약 ---\n",
            "원본 데이터 행 수: 19495\n",
            "삭제된 이상치(100g 초과): 490행\n",
            "남은 데이터 행 수: 19005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㄴ 영양값이 100g 기준으로 작성되지 않았을 가능성 있는 행 삭제"
      ],
      "metadata": {
        "id": "dEpGo63Rom9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_nutrition_data(input_df):\n",
        "    # 원본 보존을 위해 복사본 생성\n",
        "    df = input_df.copy()\n",
        "\n",
        "    # --- [1단계] 단위 추출 및 g 단위 환산 전용 임시 DF 생성 ---\n",
        "    unit_pattern = re.compile(r'\\((g|mg|ug|mcg)\\)', re.IGNORECASE)\n",
        "    unit_map = {'g': 1.0, 'mg': 0.001, 'ug': 0.000001, 'mcg': 0.000001}\n",
        "\n",
        "    # 계산만을 위한 임시 데이터프레임 (원본 df에 컬럼이 추가되지 않음)\n",
        "    temp_grams = pd.DataFrame(index=df.index)\n",
        "\n",
        "    for col in df.columns:\n",
        "        # 데이터 정제: 숫자 외 문자 제거 및 숫자 변환\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = pd.to_numeric(df[col].astype(str).str.replace(' ', ''), errors='coerce').fillna(0)\n",
        "\n",
        "        # 음수 값 0으로 보정 (원본 df 업데이트)\n",
        "        if df[col].dtype in ['float64', 'int64']:\n",
        "            df.loc[df[col] < 0, col] = 0\n",
        "\n",
        "        # 단위 매칭 및 g 환산하여 임시 DF에 저장\n",
        "        match = unit_pattern.search(col)\n",
        "        if match:\n",
        "            unit = match.group(1).lower()\n",
        "            temp_grams[col] = df[col] * unit_map[unit]\n",
        "\n",
        "    # --- [2단계] 최상위 카테고리 기반 100g 검증 ---\n",
        "    major_nutrients = ['탄수화물(g)', '단백질(g)', '지방(g)', '수분(g)', '회분(g)']\n",
        "    existing_major = [c for c in major_nutrients if c in temp_grams.columns]\n",
        "\n",
        "    # 100g 당 함량 합계 계산\n",
        "    df['total_major_grams'] = temp_grams[existing_major].sum(axis=1)\n",
        "\n",
        "    # 100.5g 임계값 적용하여 필터링된 새로운 데이터프레임 생성\n",
        "    # 기존 변수를 덮어쓰지 않고 'refined_df'에 저장\n",
        "    refined_df = df[df['total_major_grams'] <= 100.5].copy()\n",
        "\n",
        "    # --- [3단계] 정밀 에너지 교차 검증 (refined_df 대상) ---\n",
        "    def get_v(c): return refined_df[c] if c in refined_df.columns else 0\n",
        "\n",
        "    # 순수 탄수화물 계산 (탄수화물 총량 - 저에너지 성분들)\n",
        "    net_carb = (get_v('탄수화물(g)') - get_v('식이섬유(g)') - get_v('에리스리톨(g)') -\n",
        "                get_v('알룰로오스(g)') - get_v('당알콜(g)')).clip(lower=0)\n",
        "\n",
        "    # 성분별 에너지 계수 적용\n",
        "    calc_kcal = (\n",
        "        (net_carb * 4) + (get_v('단백질(g)') * 4) + (get_v('지방(g)') * 9) +\n",
        "        (get_v('식이섬유(g)') * 2) + (get_v('당알콜(g)') * 2.4)\n",
        "    )\n",
        "\n",
        "    refined_df['calculated_kcal'] = calc_kcal\n",
        "    refined_df['kcal_diff_ratio'] = (abs(refined_df['에너지(kcal)'] - calc_kcal) / (refined_df['에너지(kcal)'] + 1))\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"--- 전처리 및 검증 완료 요약 ---\")\n",
        "    print(f\"1. 입력 데이터 행 수: {len(input_df)}\")\n",
        "    print(f\"2. 이상치(100.5g 초과) 삭제 수: {len(input_df) - len(refined_df)}\")\n",
        "    print(f\"3. 정제된 데이터(refined_df) 행 수: {len(refined_df)}\")\n",
        "\n",
        "    return refined_df\n",
        "\n",
        "# 실제 사용 시\n",
        "final_result_df = preprocess_nutrition_data(cleaned_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rziwkT_oQay",
        "outputId": "d98bd7b3-ffe2-43ba-a9df-a121725a1cba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 전처리 및 검증 완료 요약 ---\n",
            "1. 입력 데이터 행 수: 19005\n",
            "2. 이상치(100.5g 초과) 삭제 수: 0\n",
            "3. 정제된 데이터(refined_df) 행 수: 19005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n",
            "/tmp/ipython-input-2003251920.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  temp_grams[col] = df[col] * unit_map[unit]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㄴ 에너지가 잘못 작성된 행 없음"
      ],
      "metadata": {
        "id": "b_stjezzog0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_result_df.to_csv('processed_nutrition_data.csv', index=False, encoding='utf-8-sig')\n",
        "final_result_df.to_excel('processed_nutrition_data.xlsx', index=False)\n",
        "print('Files processed_nutrition_data.csv and processed_nutrition_data.xlsx have been created locally.')"
      ],
      "metadata": {
        "id": "wqLpXXFTpF4n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "317dcf2d",
        "outputId": "b16f53f0-4d30-4bde-920f-e121e52799be"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "1b1b5863",
        "outputId": "097a398a-c0e0-4a8f-9b70-c0c08bd68938"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Source files from the current directory\n",
        "source_csv = 'processed_nutrition_data.csv'\n",
        "source_excel = 'processed_nutrition_data.xlsx'\n",
        "\n",
        "# Destination folder in Google Drive (create if it doesn't exist)\n",
        "destination_folder = '/content/drive/MyDrive/Nutrition_Data'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Copy the files to Google Drive\n",
        "shutil.copy(source_csv, destination_folder)\n",
        "shutil.copy(source_excel, destination_folder)\n",
        "\n",
        "print(f\"'{source_csv}' copied to '{destination_folder}'\")\n",
        "print(f\"'{source_excel}' copied to '{destination_folder}'\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'processed_nutrition_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-537157567.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Copy the files to Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_excel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed_nutrition_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzIhR4tppPrE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
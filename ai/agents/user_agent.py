from typing import List, Dict, Any, TypedDict
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.runnables import RunnableConfig



# 1. LLM êµ¬ì¡°í™” ì¶œë ¥ì„ ìœ„í•œ Pydantic ëª¨ë¸
class HealthAnalysis(BaseModel):
    """ì§ˆë³‘ ì •ë³´ì— ê¸°ë°˜í•œ ì‹ì´ ê°€ì´ë“œ ë° ì£¼ì˜ ì„±ë¶„"""
    guidelines: List[str] = Field(
        ...,
        description="í™˜ìì˜ ì§ˆë³‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ êµ¬ì²´ì ì¸ ì‹ë‹¨ ê°€ì´ë“œë¼ì¸ 3~5ê°€ì§€"
    )
    target_ingredients: List[str] = Field(
        ...,
        description="í•´ë‹¹ ì§ˆë³‘ ë³´ìœ ìê°€ í”¼í•´ì•¼ í•˜ê±°ë‚˜ ì£¼ì˜í•´ì•¼ í•  í•µì‹¬ ì„±ë¶„ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ë‚˜íŠ¸ë¥¨, ë‹¹ë¥˜, í¬í™”ì§€ë°©)"
    )

# 2. User Agent í´ë˜ìŠ¤ (ProfileRetrieval)
class ProfileRetrieval:
    def __init__(self, model):
        """
        Args:
            model: êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì§€ì›í•˜ëŠ” LLM ê°ì²´ (ì˜ˆ: ChatOpenAI)
        """
        self.llm = model
        # LLMì´ Pydantic ëª¨ë¸ì— ë§ì¶° ë‹µí•˜ë„ë¡ ì„¤ì •
        self.analysis_chain = self.llm.with_structured_output(HealthAnalysis)

    def _fetch_profile_from_backend(self, user_id: str) -> Dict[str, Any]:
        """
        [Mock API] user_idë¥¼ 'Key'ë¡œ ì‚¬ìš©í•˜ì—¬ ë°±ì—”ë“œ DBì—ì„œ ìœ ì € ì •ë³´ë¥¼ ì¡°íšŒí•¨.
        ì‹¤ì œë¡œëŠ” requests.get(f"api/user/{user_id}") í˜•íƒœê°€ ë¨.
        """
        print(f"ğŸ“¡ [User-Agent] ë°±ì—”ë“œ ì¡°íšŒ ì¤‘... (Target ID: {user_id})")

        # ì„ì‹œ DB (Mock Data)
        mock_db = {
            "user_001": {
                "name": "ê¹€ì² ìˆ˜",
                "diabetes": 1,        # ë‹¹ë‡¨ ìˆìŒ
                "hypertension": 1,    # ê³ í˜ˆì•• ìˆìŒ
                "kidneydisease": 0,
                "allergy": 0
            },
            "user_002": {
                "name": "ì´ì˜í¬",
                "diabetes": 0,
                "hypertension": 0,
                "kidneydisease": 1,   # ì‹ ì¥ì§ˆí™˜ ìˆìŒ
                "allergy": 1          # ì•ŒëŸ¬ì§€ ìˆìŒ
            }
        }

        # DBì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
        return mock_db.get(user_id, {
            "name": "Unknown", "diabetes": 0, "hypertension": 0, "kidneydisease": 0, "allergy": 0
        })

    def run(self, state: OverallState, config: RunnableConfig = None) -> Dict[str, Any]:
        """LangGraph ë…¸ë“œ ì‹¤í–‰ í•¨ìˆ˜"""

        # 1. Stateì—ì„œ user_id êº¼ë‚´ê¸° (ì´ë¯¸ ìˆëŠ” ì •ë³´ í™œìš©)
        current_user_id = state.get("user_id")

        # 2. ë°±ì—”ë“œ APIë¥¼ í†µí•´ ìƒì„¸ í”„ë¡œí•„(ì§ˆë³‘ ìœ ë¬´) ê°€ì ¸ì˜¤ê¸°
        user_profile = self._fetch_profile_from_backend(current_user_id)

        # 3. LLMì—ê²Œ ë¶„ì„ ìš”ì²­ (0/1 ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ ê°€ì´ë“œë¡œ ë³€í™˜)
        #    í”„ë¡¬í”„íŠ¸ì— ì§ˆë³‘ ì •ë³´ë¥¼ ìš”ì•½í•´ì„œ ì „ë‹¬
        health_summary = (
            f"ë‹¹ë‡¨: {'ìˆìŒ' if user_profile['diabetes'] else 'ì—†ìŒ'}, "
            f"ê³ í˜ˆì••: {'ìˆìŒ' if user_profile['hypertension'] else 'ì—†ìŒ'}, "
            f"ì‹ ì¥ì§ˆí™˜: {'ìˆìŒ' if user_profile['kidneydisease'] else 'ì—†ìŒ'}, "
            f"ì•ŒëŸ¬ì§€: {'ìˆìŒ' if user_profile['allergy'] else 'ì—†ìŒ'}"
        )

        system_msg = "ë‹¹ì‹ ì€ ì„ìƒ ì˜ì–‘ì‚¬ì…ë‹ˆë‹¤. í™˜ìì˜ ì§ˆë³‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ë‹¨ ê°€ì´ë“œì™€ ì£¼ì˜ ì„±ë¶„ì„ ì¶”ì¶œí•˜ì„¸ìš”."

        # LLM í˜¸ì¶œ (êµ¬ì¡°í™”ëœ ì¶œë ¥ ë°˜í™˜)
        analysis_result: HealthAnalysis = self.analysis_chain.invoke([
            SystemMessage(content=system_msg),
            HumanMessage(content=f"í™˜ì ì •ë³´: {health_summary}")
        ])

        print(f"âœ… [User-Agent] ë¶„ì„ ì™„ë£Œ: {analysis_result.target_ingredients}")

        # 4. State ì—…ë°ì´íŠ¸ (ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ ë°˜í™˜)
        return {
            # (1) ë°±ì—”ë“œì—ì„œ ê°€ì ¸ì˜¨ Raw Data
            "name": user_profile["name"],
            "diabetes": user_profile["diabetes_flag"],
            "hypertension": user_profile["hypertension_flag"],
            "kidneydisease": user_profile["kidneydisease_flag"],
            "allergy": user_profile["allergy_flag"],

            "diabetes_type": user_profile["diabetes_detail"],
            "hypertension_type": user_profile["hypertension_detail"],
            "kidneydisease_type": user_profile["kidneydisease_detail"],
            "allergy_list": user_profile["allergy_list"],

            "final_profile": user_profile, # ì„ê³„ê°’

            # (4) íë¦„ ì œì–´ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ê²Œ í„´ì„ ë„˜ê¹€)
            "next_step": "orch_agent"
        }

# --- ì‚¬ìš© ì˜ˆì‹œ ---

# 1. LLM ì •ì˜ (ì•ì„œ ë§Œë“  router_llmê³¼ ê°™ì€ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥)
# from langchain_openai import ChatOpenAI
# retrieval_llm = ChatOpenAI(model="gpt-4o", temperature=0)

# 2. í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
useragent = ProfileRetrieval(retrieval_llm)

# 3. LangGraphì— ë…¸ë“œ ì¶”ê°€ ì‹œ
# workflow.add_node("user_agent", useragent.run)
